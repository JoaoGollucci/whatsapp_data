# BigQuery Data Monitor - Cloud Run Job

Monitor de dados no BigQuery com alertas por email quando dados est√£o ausentes.

## üöÄ Deploy no Cloud Run Job

```bash
gcloud run jobs deploy bq-data-monitor \
  --source . \
  --region us-central1 \
  --set-env-vars "GCP_PROJECT_ID=gauge-prod" \
  --set-env-vars "BQ_DATASET_TABLE=projeto_meli.vw_aff_quantity" \
  --set-env-vars "BQ_DATE_COLUMN=date" \
  --set-env-vars "DAYS_BACK=1" \
  --set-env-vars "ALERT_EMAIL_TO=seu-email@exemplo.com" \
  --set-env-vars "SMTP_USER=seu-email@gmail.com" \
  --set-env-vars "SMTP_PASSWORD=sua-senha-app" \
  --max-retries 0 \
  --task-timeout 300
```

## üìã Vari√°veis de Ambiente Obrigat√≥rias

| Vari√°vel | Descri√ß√£o | Exemplo |
|----------|-----------|---------|
| `GCP_PROJECT_ID` | ID do projeto GCP | `gauge-prod` |
| `BQ_DATASET_TABLE` | Dataset.Tabela no BigQuery | `projeto_meli.vw_aff_quantity` |
| `BQ_DATE_COLUMN` | Nome da coluna de data | `date` |
| `DAYS_BACK` | Quantos dias atr√°s verificar (D-N) | `1` |
| `ALERT_EMAIL_TO` | Email para receber alertas | `alerta@exemplo.com` |
| `SMTP_USER` | Usu√°rio SMTP (email remetente) | `monitor@gmail.com` |
| `SMTP_PASSWORD` | Senha ou App Password do SMTP | `xxxx xxxx xxxx xxxx` |

## üìã Vari√°veis Opcionais

| Vari√°vel | Descri√ß√£o | Padr√£o |
|----------|-----------|--------|
| `SMTP_SERVER` | Servidor SMTP | `smtp.gmail.com` |
| `SMTP_PORT` | Porta SMTP | `587` |

## üîç Como Funciona

1. **Conecta ao BigQuery** usando as credenciais da service account do Cloud Run
2. **Executa a query** verificando dados de D-N (ex: D-1 = ontem)
3. **Verifica resultados**:
   - ‚úÖ Dados encontrados ‚Üí Script termina com sucesso (exit 0)
   - ‚ùå Dados ausentes ‚Üí Envia email de alerta (exit 1)
   - üí• Erro cr√≠tico ‚Üí Envia email de erro (exit 1)

## üîß Permiss√µes Necess√°rias

A service account do Cloud Run Job precisa de permiss√µes no BigQuery:

```bash
# Dar permiss√£o de leitura no dataset
gcloud projects add-iam-policy-binding gauge-prod \
  --member='serviceAccount:PROJECT-NUMBER-compute@developer.gserviceaccount.com' \
  --role='roles/bigquery.dataViewer'

# Dar permiss√£o para executar jobs
gcloud projects add-iam-policy-binding gauge-prod \
  --member='serviceAccount:PROJECT-NUMBER-compute@developer.gserviceaccount.com' \
  --role='roles/bigquery.jobUser'
```

## üìß Configurar Gmail (recomendado)

1. **Ativar verifica√ß√£o em 2 etapas** na sua conta Google
2. **Gerar App Password**:
   - Acesse: https://myaccount.google.com/apppasswords
   - Crie uma senha de app para "Mail"
   - Use essa senha em `SMTP_PASSWORD`

## ‚è∞ Agendar Execu√ß√£o (Cloud Scheduler)

```bash
# Criar scheduler para executar diariamente √†s 8h
gcloud scheduler jobs create http bq-data-check \
  --location us-central1 \
  --schedule="0 8 * * *" \
  --time-zone="America/Sao_Paulo" \
  --uri="https://us-central1-run.googleapis.com/apis/run.googleapis.com/v1/namespaces/gauge-prod/jobs/bq-data-monitor:run" \
  --http-method POST \
  --oauth-service-account-email PROJECT-NUMBER-compute@developer.gserviceaccount.com
```

### Exemplos de Schedule (Cron):
- `0 8 * * *` - Todo dia √†s 8h
- `0 */6 * * *` - A cada 6 horas
- `0 8,18 * * *` - √Äs 8h e 18h
- `0 8 * * 1-5` - Dias √∫teis √†s 8h

## üß™ Testar Localmente

```bash
# Instalar depend√™ncias
pip install google-cloud-bigquery

# Autenticar com GCP
gcloud auth application-default login

# Configurar vari√°veis
export GCP_PROJECT_ID="gauge-prod"
export BQ_DATASET_TABLE="projeto_meli.vw_aff_quantity"
export BQ_DATE_COLUMN="date"
export DAYS_BACK="1"
export ALERT_EMAIL_TO="seu-email@exemplo.com"
export SMTP_USER="seu-email@gmail.com"
export SMTP_PASSWORD="sua-senha-app"

# Executar
python check_data.py
```

## üìä Email de Alerta

### Quando h√° dados ausentes:
- üö® Assunto: "ALERTA: Dados ausentes no BigQuery - YYYY-MM-DD"
- Detalhes da query executada
- Sugest√µes de verifica√ß√£o

### Quando h√° erro cr√≠tico:
- üí• Assunto: "ERRO CR√çTICO: Falha na verifica√ß√£o BigQuery"
- Mensagem de erro detalhada

## üîç Monitorar Execu√ß√µes

```bash
# Ver logs
gcloud logging read "resource.type=cloud_run_job AND resource.labels.job_name=bq-data-monitor" --limit 50

# Ver execu√ß√µes
gcloud run jobs executions list --job=bq-data-monitor --region=us-central1

# Executar manualmente
gcloud run jobs execute bq-data-monitor --region=us-central1
```

## üí° Casos de Uso

- **Monitoramento de Pipeline ETL** - Verificar se dados foram processados
- **Valida√ß√£o de Carga Di√°ria** - Garantir que dados do dia anterior existem
- **Alertas de Falha de Ingest√£o** - Detectar problemas no pipeline de dados
- **SLA de Dados** - Garantir disponibilidade de dados para stakeholders

## üí∞ Custos Estimados

- **Cloud Run Jobs**: ~$0.10/m√™s (1 execu√ß√£o/dia)
- **BigQuery**: Inclu√≠do no free tier (queries < 1TB/m√™s)
- **Cloud Scheduler**: ~$0.10/m√™s
- **Total**: ~$0.20/m√™s
